{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Baye's Theorem\nIn order to understand **Naive Bayes Classification**, one first must understand **Baye's Theorem**\n\n## **Scenario**: \n### There are **5** marbles in a bag. **3** of these marbles are white and **2** of these marbles are black. Given that the first marble we pulled was a **black** marble, what is the probability that the next marble will also be **black**?\n","metadata":{}},{"cell_type":"markdown","source":"![](http://i.postimg.cc/Y2stPGqg/Bayetheorem.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Naive Baye's Classifier\nThe Naive Baye's Classifier modifies and utilizes the Baye's Theoreom to accomoplish it's objective. Various types of Naive Bayes Classifiers include:\n\n- **Multinomial**\n- **Gaussian**\n- **Bernoulli**\n\nIn this tutorial we will utilize Multinomial and Bernoulli Naive Baye's Classifiers. This is significant because we will accomplish this through a spam detection. Within this model we will be able to demonstrate the difference between the Bernoulli approach vs the Multinomial. Key Notes:\n\n- Bernoulli : Utilizes the frequency of a specific word within our model as well as the event that the word does not occur. Thus it explicitly penalizes the non-occurrence of a feature \n- Multinomial : Utilizes the relative frequency count to estimate the the probability of a feature appearing in a sample. This is important because it does not penalize the non occurance of the feature but instead it implements smoothing (Laplace or Lidstone) to account for the non occurance of various features.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Processing of Raw Email Data\n![](https://i.postimg.cc/Hk0BPN1N/emailcleansing.jpg)","metadata":{}},{"cell_type":"markdown","source":"## We will utlize this method to cleanse our emails in preparation for analysis. There are also functions to utlize lowercases, removal of punctuations etc. When we start changing our cases various words take on different meanings. For example 'Mark' could be utilized as someone's name but as we decrease the case to 'mark' it tends to have the same representation as the verb mark.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_curve, roc_auc_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:35.234908Z","iopub.execute_input":"2023-07-11T23:12:35.235344Z","iopub.status.idle":"2023-07-11T23:12:35.242897Z","shell.execute_reply.started":"2023-07-11T23:12:35.235308Z","shell.execute_reply":"2023-07-11T23:12:35.241902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load sms-spam-collection-dataset\ndf = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\", encoding=\"latin1\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:35.244932Z","iopub.execute_input":"2023-07-11T23:12:35.246014Z","iopub.status.idle":"2023-07-11T23:12:35.313502Z","shell.execute_reply.started":"2023-07-11T23:12:35.245967Z","shell.execute_reply":"2023-07-11T23:12:35.312283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:35.315618Z","iopub.execute_input":"2023-07-11T23:12:35.316505Z","iopub.status.idle":"2023-07-11T23:12:35.326145Z","shell.execute_reply.started":"2023-07-11T23:12:35.316447Z","shell.execute_reply":"2023-07-11T23:12:35.324684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will begin by cleansing deleting the empty columns and creating a boolean column for spam classification\n# Drop the last three columns iteratively\n\nfor i in range(3):\n    df = df.drop(df.columns[-1], axis=1)    # Drop last three empty columns \n    \ndf['spam']= df['v1'].apply(lambda x:1 if x=='spam' else 0)  #Create boolean of spam or ham\n\ndf = df.rename(columns={'v2': 'Text'})   #Rename column v2 to text\n\ndf = df.drop('v1', axis=1)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:35.328473Z","iopub.execute_input":"2023-07-11T23:12:35.328960Z","iopub.status.idle":"2023-07-11T23:12:35.361829Z","shell.execute_reply.started":"2023-07-11T23:12:35.328912Z","shell.execute_reply":"2023-07-11T23:12:35.360445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the stopwords from NLTK\nstopwords = set(stopwords.words('english'))\n\n# Instantiate the PorterStemmer\nstemmer = PorterStemmer()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:35.365082Z","iopub.execute_input":"2023-07-11T23:12:35.365835Z","iopub.status.idle":"2023-07-11T23:12:35.381076Z","shell.execute_reply.started":"2023-07-11T23:12:35.365783Z","shell.execute_reply":"2023-07-11T23:12:35.379797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing steps\ndef preprocess(text):\n    # Remove special characters and numbers\n    text = re.sub('[^a-zA-Z]', ' ', text)\n\n    # Convert to lowercase\n    text = text.lower()\n\n    # Tokenization\n    tokens = text.split()\n\n    # Remove stopwords\n    tokens = [token for token in tokens if token not in stopwords]\n\n    # Stemming\n    tokens = [stemmer.stem(token) for token in tokens]\n\n    # Join the tokens back into a single string\n    text = ' '.join(tokens)\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:35.382758Z","iopub.execute_input":"2023-07-11T23:12:35.383163Z","iopub.status.idle":"2023-07-11T23:12:35.391305Z","shell.execute_reply.started":"2023-07-11T23:12:35.383126Z","shell.execute_reply":"2023-07-11T23:12:35.390076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply preprocessing to the 'text' column\ndf['processed_text'] = df['Text'].apply(preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:35.392760Z","iopub.execute_input":"2023-07-11T23:12:35.393395Z","iopub.status.idle":"2023-07-11T23:12:37.295478Z","shell.execute_reply.started":"2023-07-11T23:12:35.393358Z","shell.execute_reply":"2023-07-11T23:12:37.294489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an instance of CountVectorizer\nvectorizer = CountVectorizer()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.297117Z","iopub.execute_input":"2023-07-11T23:12:37.297487Z","iopub.status.idle":"2023-07-11T23:12:37.302548Z","shell.execute_reply.started":"2023-07-11T23:12:37.297455Z","shell.execute_reply":"2023-07-11T23:12:37.301172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above code allows us to  utilize CountVectorizer's functionality for transforming the text data into a numerical representation suitable for machine learning algorithms.It converts a collection of text documents into a matrix of token counts. Each document is represented as a vector, where each element of the vector corresponds to the count of a specific word or token in the document.","metadata":{}},{"cell_type":"code","source":"# Fit and transform the preprocessed text data\nX = vectorizer.fit_transform(df['processed_text'])\n\n#This is basically transforming the processed text data into a matrix of token counts using the vectorizer","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.304201Z","iopub.execute_input":"2023-07-11T23:12:37.304707Z","iopub.status.idle":"2023-07-11T23:12:37.420901Z","shell.execute_reply.started":"2023-07-11T23:12:37.304662Z","shell.execute_reply":"2023-07-11T23:12:37.419905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['processed_text'].dtype","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.422703Z","iopub.execute_input":"2023-07-11T23:12:37.423151Z","iopub.status.idle":"2023-07-11T23:12:37.430671Z","shell.execute_reply.started":"2023-07-11T23:12:37.423105Z","shell.execute_reply":"2023-07-11T23:12:37.429629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['spam'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.432339Z","iopub.execute_input":"2023-07-11T23:12:37.432932Z","iopub.status.idle":"2023-07-11T23:12:37.445277Z","shell.execute_reply.started":"2023-07-11T23:12:37.432897Z","shell.execute_reply":"2023-07-11T23:12:37.444267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the document-term matrix\nprint(X.toarray())","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.447021Z","iopub.execute_input":"2023-07-11T23:12:37.447470Z","iopub.status.idle":"2023-07-11T23:12:37.557954Z","shell.execute_reply.started":"2023-07-11T23:12:37.447426Z","shell.execute_reply":"2023-07-11T23:12:37.556708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.562236Z","iopub.execute_input":"2023-07-11T23:12:37.562612Z","iopub.status.idle":"2023-07-11T23:12:37.574721Z","shell.execute_reply.started":"2023-07-11T23:12:37.562578Z","shell.execute_reply":"2023-07-11T23:12:37.573460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Test effectiveness of Multinomial Model vs Bernoulli Model on spam detection\n","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, df['spam'], test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.577051Z","iopub.execute_input":"2023-07-11T23:12:37.577630Z","iopub.status.idle":"2023-07-11T23:12:37.591899Z","shell.execute_reply.started":"2023-07-11T23:12:37.577581Z","shell.execute_reply":"2023-07-11T23:12:37.590745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MultinomialNB()\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.593696Z","iopub.execute_input":"2023-07-11T23:12:37.594177Z","iopub.status.idle":"2023-07-11T23:12:37.611392Z","shell.execute_reply.started":"2023-07-11T23:12:37.594134Z","shell.execute_reply":"2023-07-11T23:12:37.610282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the training set\ny_train_pred = model.predict(X_train)\n\n# Predict on the testing set\ny_test_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.613168Z","iopub.execute_input":"2023-07-11T23:12:37.613576Z","iopub.status.idle":"2023-07-11T23:12:37.621181Z","shell.execute_reply.started":"2023-07-11T23:12:37.613541Z","shell.execute_reply":"2023-07-11T23:12:37.620075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate and print accuracy score\ntrain_accuracy = accuracy_score(y_train, y_train_pred)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(\"Training Accuracy:\", train_accuracy)\nprint(\"Testing Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.622135Z","iopub.execute_input":"2023-07-11T23:12:37.622557Z","iopub.status.idle":"2023-07-11T23:12:37.635526Z","shell.execute_reply.started":"2023-07-11T23:12:37.622525Z","shell.execute_reply":"2023-07-11T23:12:37.634364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test with Bernoullli\nBmodel = BernoulliNB()\nBmodel.fit(X_train, y_train)\n\n# Predict on the training set\nBy_train_pred = Bmodel.predict(X_train)\n\n# Predict on the testing set\nBy_test_pred = Bmodel.predict(X_test)\n\n# Calculate and print accuracy score\ntrain_accuracy = accuracy_score(y_train, By_train_pred)\ntest_accuracy = accuracy_score(y_test, By_test_pred)\nprint(\"Training Accuracy:\", train_accuracy)\nprint(\"Testing Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.636986Z","iopub.execute_input":"2023-07-11T23:12:37.637369Z","iopub.status.idle":"2023-07-11T23:12:37.654312Z","shell.execute_reply.started":"2023-07-11T23:12:37.637335Z","shell.execute_reply":"2023-07-11T23:12:37.653062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate ROC curve and AUC for MultinomialNB\nfpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\nauc = roc_auc_score(y_test, y_test_pred)\n\n# Plot ROC curve for MultinomialNB\nplt.plot(fpr, tpr, label='MultinomialNB (AUC = {:.2f})'.format(auc))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.655787Z","iopub.execute_input":"2023-07-11T23:12:37.656142Z","iopub.status.idle":"2023-07-11T23:12:37.922564Z","shell.execute_reply.started":"2023-07-11T23:12:37.656105Z","shell.execute_reply":"2023-07-11T23:12:37.921367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute confusion matrix for MultinomialNB\nmultinomial_nb_cm = confusion_matrix(y_test, y_test_pred)\n\n# Visualize confusion matrix for MultinomialNB\nplt.figure(figsize=(8, 6))\nsns.heatmap(multinomial_nb_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.title(\"Confusion Matrix - MultinomialNB\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:37.923904Z","iopub.execute_input":"2023-07-11T23:12:37.924272Z","iopub.status.idle":"2023-07-11T23:12:38.190719Z","shell.execute_reply.started":"2023-07-11T23:12:37.924213Z","shell.execute_reply":"2023-07-11T23:12:38.189516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate ROC curve and AUC for BernoulliNB\nfpr, tpr, thresholds = roc_curve(y_test, By_test_pred)\nauc = roc_auc_score(y_test, By_test_pred)\n\n# Plot ROC curve for BernoulliNB\nplt.plot(fpr, tpr, label='BernoulliNB (AUC = {:.2f})'.format(auc))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:38.192065Z","iopub.execute_input":"2023-07-11T23:12:38.192437Z","iopub.status.idle":"2023-07-11T23:12:38.419330Z","shell.execute_reply.started":"2023-07-11T23:12:38.192395Z","shell.execute_reply":"2023-07-11T23:12:38.418038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute confusion matrix for BernoulliNB\nbernoulli_nb_cm = confusion_matrix(y_test, By_test_pred)\n\n# Visualize confusion matrix for BernoulliNB\nplt.figure(figsize=(8, 6))\nsns.heatmap(bernoulli_nb_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.title(\"Confusion Matrix - BernoulliNB\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:38.420652Z","iopub.execute_input":"2023-07-11T23:12:38.420969Z","iopub.status.idle":"2023-07-11T23:12:38.685511Z","shell.execute_reply.started":"2023-07-11T23:12:38.420938Z","shell.execute_reply":"2023-07-11T23:12:38.684242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nlabel_names = ['ham', 'spam']\nfrom sklearn.metrics import accuracy_score\n\n# Create an instance of GaussianNB\ngaussian_nb = GaussianNB()\ngaussian_nb.fit(X_train.toarray(), y_train)\n\n# Predict on the training set\ny_train_pred_gaussian = gaussian_nb.predict(X_train.toarray())\n\n# Predict on the testing set\ny_test_pred_gaussian = gaussian_nb.predict(X_test.toarray())\n\n# Calculate and print accuracy score for training set\ntrain_accuracy_gaussian = accuracy_score(y_train, y_train_pred_gaussian)\nprint(\"GaussianNB Training Accuracy:\", train_accuracy_gaussian)\n\n# Calculate and print accuracy score for testing set\ntest_accuracy_gaussian = accuracy_score(y_test, y_test_pred_gaussian)\nprint(\"GaussianNB Testing Accuracy:\", test_accuracy_gaussian)\n\n# Compute confusion matrix for GaussianNB\ngaussian_nb_cm = confusion_matrix(y_test, y_test_pred_gaussian)\n\n# Visualize confusion matrix for GaussianNB\nplt.figure(figsize=(8, 6))\nsns.heatmap(gaussian_nb_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_names, yticklabels=label_names)\nplt.title(\"Confusion Matrix - GaussianNB\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-11T23:12:38.686720Z","iopub.execute_input":"2023-07-11T23:12:38.687031Z","iopub.status.idle":"2023-07-11T23:12:40.161753Z","shell.execute_reply.started":"2023-07-11T23:12:38.687001Z","shell.execute_reply":"2023-07-11T23:12:40.160643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n## The MultinomialNB model demonstrated the best performance among the three models for spam detection. It achieved the highest accuracy on both the training and testing sets. The MultinomialNB algorithm is well-suited for text classification tasks, such as spam detection, where the features are discrete and represent the occurrence counts of words.","metadata":{}}]}